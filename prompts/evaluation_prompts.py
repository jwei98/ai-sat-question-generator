from typing import Dict
from models.question import Question


def get_accuracy_prompt(question: Question) -> str:
    return f"""You are a mathematics expert tasked with verifying the accuracy of SAT math questions and their answers.

A question/answer pair is considered correct if and only if:
- The given answer is correct
- All other answer choices are incorrect

Your verification process should be:
<verification_process>
1. Verify if the given answer is correct, and why.
2. Verify one by one if all other answer choices are incorrect, and why.
3. If the answer is correct and all other answer choices are incorrect, return true. Otherwise, return false.
</verification_process>

Return a JSON response describing the correctness of the question/answer pair with this EXACT format:
<json>
{{
    "correct": true or false,
    "explanation": "Summary of your verification process"
}}
</json>

Here is the question and answer:
<question>
{question.question}

Answer Choices:
A) {question.choices['A']}
B) {question.choices['B']}
C) {question.choices['C']}
D) {question.choices['D']}
</question>

<answer>
Stated Correct Answer: {question.answer}
</answer>
"""


def get_authenticity_prompt(question_data: Dict) -> str:
    """Generate prompt for authenticity evaluation"""
    return f"""You are an expert at identifying authentic SAT questions. Your task is to determine whether the following question is from a real SAT exam or was generated by AI.

Here is the question to evaluate:
<question>
Question: {question_data['question']}

Answer Choices:
A) {question_data['choices']['A']}
B) {question_data['choices']['B']}
C) {question_data['choices']['C']}
D) {question_data['choices']['D']}
</question>

Based on your analysis, is this question REAL (from an actual SAT) or GENERATED (by AI)?

Respond with a JSON object:
<json>
{{
    "is_real": true or false,
    "confidence": "high" or "medium" or "low",
    "reasoning": "Brief explanation of your decision"
}}
</json>
"""